const EpilogueCh = () => {
    return (
        <div>
      <h1 className="chapter" id="c11">
        <a id="page222"></a>
        <strong>Chapter</strong> ∞
      </h1>
      <h1 className="subchapter">
        <strong>Epilogue: How Math Helps Us Think About Weird Things</strong>
      </h1>
      <h1
        className="subchapterpre"
        style="margin-top:-7em; margin-left:3.5em; margin-bottom:5.0em;"
      >
        <strong>by Michael Shermer</strong>
      </h1>
      <p className="nonindent">
        <strong>
          <span className="big">A</span>
        </strong>
        s the publisher of <em>Skeptic</em> magazine, the executive director of
        the Skeptics Society, and a <em>Scientific American</em> editor with a
        monthly column entitled “Skeptic,” I receive volumes of mail from people
        who challenge me with stories about their unusual experiences, such as
        haunted houses, ghosts, near-death and out-of-body experiences, UFO
        sightings, alien abductions, death-premonition dreams, and much more.
      </p>
      <p className="indent">
        The most interesting stories to me are those about highly improbable
        events. The implication of the letter writer’s tale is that if I cannot
        offer a satisfactory <em>natural</em> explanation for{" "}
        <em>that particular event</em>, the general principle of{" "}
        <em>supernaturalism</em> is preserved. A common story is the one about
        having a dream about the death of a friend or relative, then a phone
        call comes the next day about the unexpected death of the person in the
        dream. What are the odds of that? I am asked.
      </p>
      <p className="indent">
        Here is where math comes in to play in our thinking and reasoning. I
        don’t want to pontificate about how mathematics in school teaches
        students to think critically, because that has <a id="page223"></a>
        probably been said by nearly every math teacher in nearly every math
        class in nearly every school in America, at least once a year. I want to
        give some specific examples of how I use very simple math to help me on
        the job in explaining why weird things happen to people.
      </p>
      <p className="indent">
        Although I cannot always explain such specific occurrences, a principle
        of probability called the Law of Large Numbers shows that an event with
        a low probability of occurrence in a small number of trials has a high
        probability of occurrence in a large number of trials. Or, as I like to
        say, million-to-one odds happen 295 times a day in America.
      </p>
      <p className="indent">
        Let’s begin with death premonitions. Here is a little
        “back-of-the-envelope” calculation I did. Psychologists tell us that the
        average person has about five dreams per day, which equals 1,825 dreams
        per year. Even if we remember only one out of ten dreams, that still
        results in 182.5 remembered dreams a year. There are 295 million
        Americans, so that means there will be 53.8 billion remembered dreams
        per year. Now, anthropologists and sociologists tell us that each of us
        knows about 150 people fairly well (that is, the average person has
        about 150 names in his or her address book about which can be said
        something significant). That means there is a network grid of 44.3
        billion personal relationships among those 295 million Americans. The
        annual U.S. death rate from all causes across all ages is .008, or 2.6
        million per year. It is inevitable that some of those 53.8 billion
        remembered dreams will be about some of these 2.6 million deaths among
        the 295 million Americans and their 44.3 billion relationships.{" "}
        <em>
          It would be a miracle, in fact, if some “death premonition” dreams did
          not come true
        </em>
        .
      </p>
      <p className="indent">
        Even if my numbers are off, even way off, the point still stands. What
        are the odds of a death premonition dream coming true? Pretty darn good.
      </p>
      <p className="indent">
        <a id="page224"></a>There is an additional psychological factor at work
        here called the <em>confirmation bias</em>, where we notice the hits and
        ignore the misses in support of our favorite beliefs. The confirmation
        bias explains how conspiracy theories work, for example. People who
        adhere to a particular conspiracy theory (9/11 was orchestrated by the
        Bush administration in order to launch a war in the Middle East), will
        look for and find little factoids here and there that seem to indicate
        that it might be true (Bush sat in that classroom reading to the
        children about goats as if he knew he was safe), while ignoring the vast
        body of evidence that points to another more likely explanation (Osama
        bin Laden and his band of international terrorists orchestrated 9/11).
        The confirmation bias also helps explain how astrologers, tarot-card
        readers, and psychics seem so successful at “reading” people. People who
        get a reading are likely to remember the handful of hits and forget the
        countless misses. When such hits and misses are actually counted—which I
        once did for an ABC television special on psychics—it turns out that
        there is nothing more than guessing and random chance at work.
      </p>
      <p className="indent">
        In the case of the death-premonition dream, if just a couple of these
        people who have such dreams recount their miraculous tales in a public
        forum (next on <em>Oprah</em>!), the paranormal seems vindicated. In
        fact, it is nothing more than the laws of probability writ large.
      </p>
      <p className="indent">
        This mathematical process of thinking about weird things led me to
        another back-of-the-envelope calculation about miracles. People
        typically invoke the term <em>miracle</em> to describe really unusual
        events, events whose odds of occurring are a “million to one.” Okay,
        let’s take that as our benchmark definition. A miracle is an event whose
        odds of occurrence are a million to one. Now, as we go about our day, we
        see and hear things happen about once per second. That is, data from the
        world and <a id="page225"></a>events around us are pouring in through
        our senses at a rate of about one per second. If we are awake and alert
        and out in the world for, say, eight hours a day, that means there are
        thirty thousand bits of data per day, or one million events per month
        that we take in. The vast majority of these data and events are
        completely meaningless, of course, and our brains are wired to filter
        out and forget the vast majority of them because we would be overwhelmed
        otherwise. But, in the course of a month, we would expect million-to-one
        odds to happen at least once. Add to that the confirmation bias where we
        will remember the most unusual events and forget all the rest, and it is
        inevitable that someone somewhere will report a miracle every month. And
        the tabloids will be there to record it!
      </p>
      <p className="indent">
        This is a short primer on how science works. In our quest to understand
        how the world works, we need to determine what is real and what is not,
        what happens by chance and what happens because of some particular
        predictable cause. The problem we face is that the human brain was
        designed by evolution to pay attention to the really unusual events and
        ignore the vast body of data flowing by; as such, thinking statistically
        and with probabilities does not come naturally. Science, to that extent,
        does not come naturally. It takes some training and practice.
      </p>
      <p className="indent">
        In addition, there are those pesky cognitive biases I mentioned, such as
        the confirmation bias. And there are others. The data do not just speak
        for themselves. Data are filtered through very subjective and biased
        brains. The <em>self-serving bias</em>, for example, dictates that we
        tend to see ourselves in a more positive light than others see us:
        national surveys show that most business people believe they are more
        moral than other business people, while psychologists who study moral
        intuition think they are more moral than other such psychologists. In
        one College Entrance Examination Board survey of 829,000 high school{" "}
        <a id="page226"></a>seniors, 0 percent rated themselves below average in
        “ability to get along with others,” while 60 percent put themselves in
        the top 10 percent (presumably not all were from Lake Woebegone). And
        according to a 1997 <em>U.S. News &amp; World Report</em> study on who
        Americans believe are most likely to go to heaven, 52 percent said Bill
        Clinton, 60 percent thought Princess Diana, 65 percent chose Michael
        Jordan, 79 percent selected Mother Teresa, and, at 87 percent, the
        person most likely to go to heaven was the survey taker!
      </p>
      <p className="indent">
        Princeton University psychology professor Emily Pronin and her
        colleagues tested a bias called <em>blind spot</em>, in which subjects
        recognized the existence and influence in others of eight different
        cognitive biases, but they failed to see those same biases in
        themselves. In one study on Stanford University students, when asked to
        compare themselves to their peers on such personal qualities as
        friendliness and selfishness, they predictably rated themselves higher.
        Even when the subjects were warned about the{" "}
        <em>better-than-average bias</em> and were asked to reevaluate their
        original assessments, 63 percent claimed that their initial evaluations
        were objective, and 13 percent even claimed that they were originally
        too modest! In a second study, Pronin randomly assigned subjects high or
        low scores on a “social intelligence” test. Unsurprisingly, those given
        the high marks rated the test fairer and more useful than those
        receiving low marks. When asked if it was possible that they had been
        influenced by the score on the test, subjects responded that{" "}
        <em>other</em> participants had been far more biased than they were. In
        a third study in which Pronin queried subjects about what method they
        used to assess their own and others’ biases, she found that people tend
        to use general theories of behavior when evaluating others, but use
        introspection when appraising <a id="page227"></a>themselves; however,
        in what is called the <em>introspection illusion</em>, people do not
        believe that others can be trusted to do the same. Okay for me but not
        for thee.
      </p>
      <p className="indent">
        The University of California at Berkeley psychologist Frank J. Sulloway
        and I made a similar discovery of an <em>attribution bias</em> in a
        study we conducted on why people say they believe in God, and why they
        think other people believe in God. In general, most people attribute
        their own belief in God to such intellectual reasons as the good design
        and complexity of the world, whereas they attribute others’ belief in
        God to such emotional reasons as it is comforting, gives meaning, and
        that they were raised to believe. Political scientists have made a
        similar discovery about political attitudes, where Republicans justify
        their conservative attitudes with rational arguments but claim that
        Democrats are “bleeding-heart liberals,” and where Democrats claim that
        their liberal attitudes are the most rational but claim that Republicans
        are “heartless.”
      </p>
      <p className="indent">
        How does science deal with such subjective biases? How do we know when a
        claim is bogus or real? We want to be open-minded enough to accept
        radical new ideas when they occasionally come along, but we don’t want
        to be so open-minded that our brains fall out. This problem led us at
        the Skeptics Society to create an educational tool called the Baloney
        Detection Kit, inspired by Carl Sagan’s discussion of how to detect
        “baloney” in his marvelous book <em>The Demon-Haunted World</em>. In
        this Baloney Detection Kit, we suggest ten questions to ask when
        encountering any claim that can help us decide if we are being too
        open-minded in accepting it or too closed-minded in rejecting it.
      </p>
      <p className="extract">
        <strong>1. How reliable is the source of the claim?</strong> As Daniel
        Kevles showed so effectively in his 1999 book{" "}
        <em>The Baltimore Affair</em>, in <a id="page228"></a>investigating
        possible scientific fraud there is a boundary problem in detecting a
        fraudulent signal within the background noise of mistakes and sloppiness
        that is a normal part of the scientific process. The investigation of
        research notes in a laboratory affiliated with Nobel laureate David
        Baltimore by an independent committee established by Congress to
        investigate potential fraud revealed a surprising number of mistakes.
        But science is messier than most people realize. Baltimore was
        exonerated when it became clear that there was no purposeful data
        manipulation.
      </p>
      <p className="extract">
        <strong>2. Does this source often make similar claims?</strong>{" "}
        Pseudoscientists have a habit of going well beyond the facts, so when
        individuals make numerous extraordinary claims, they may be more than
        just iconoclasts. This is a matter of quantitative scaling, since some
        great thinkers often go beyond the data in their creative speculations.
        Cornell’s Thomas Gold is notorious for his radical ideas, but he has
        been right often enough that other scientists listen to what he has to
        say. Gold proposes, for example, that oil is not a fossil fuel at all,
        but the by-product of a deep hot biosphere. Hardly any earth scientists
        I have spoken with take this thesis seriously, yet they do not consider
        Gold a crank. What we are looking for here is a pattern of fringe
        thinking that consistently ignores or distorts data.
      </p>
      <p className="extract">
        <strong>3. Have the claims been verified by another source?</strong>{" "}
        Typically pseudoscientists will make statements that are unverified, or
        verified by a source within their own belief circle. We must ask who is
        checking the claims, and even who is checking the checkers. The biggest
        problem with the cold fusion debacle, for example, was not that
        scientists Stanley Pons and Martin Fleischman were wrong; it was that
        they announced their spectacular discovery before it was verified by
        other laboratories (at a press <a id="page229"></a>conference no less),
        and, worse, when cold fusion was not replicated, they continued to cling
        to their claim.
      </p>
      <p className="extract">
        <strong>
          4. How does the claim fit with what we know about how the world works?
        </strong>{" "}
        An extraordinary claim must be placed into a larger context to see how
        it fits. When people claim that the pyramids and the Sphinx were built
        more than ten thousand years ago by an advanced race of humans, they are
        not presenting any context for that earlier civilization. Where are the
        rest of the artifacts of those people? Where are their works of art,
        their weapons, their clothing, their tools, their trash? This is simply
        not how archaeology works.
      </p>
      <p className="extract">
        <strong>
          5. Has anyone gone out of the way to disprove the claim, or has only
          confirmatory evidence been sought?
        </strong>{" "}
        This is the confirmation bias, or the tendency to seek confirmatory
        evidence and reject or ignore disconfirmatory evidence. The confirmation
        bias is powerful and pervasive and is almost impossible for any of us to
        avoid. It is why the methods of science that emphasize checking and
        rechecking, verification and replication, and especially attempts to
        falsify a claim are so critical.
      </p>
      <p className="extract">
        <strong>
          6. Does the preponderance of evidence converge to the claimant’s
          conclusion, or a different one?
        </strong>{" "}
        The theory of evolution, for example, is proven through a convergence of
        evidence from a number of independent lines of inquiry. No one fossil,
        no one piece of biological or paleontological evidence has “evolution”
        written on it; instead there is a convergence of evidence from tens of
        thousands of evidentiary bits that adds up to a story of the evolution
        of life. Creationists conveniently ignore this convergence, focusing
        instead on trivial anomalies or currently unexplained phenomena in the
        history of life. <a id="page230"></a>
      </p>
      <p className="extract">
        <strong>
          7. Is the claimant employing the accepted rules of reason and tools of
          research, or have these been abandoned in favor of others that lead to
          the desired conclusion?
        </strong>{" "}
        UFOlogists suffer this fallacy in their continued focus on a handful of
        unexplained atmospheric anomalies and visual misperceptions by
        eyewitnesses, while conveniently ignoring the fact that the vast
        majority (90 to 95 percent) of UFO sightings are fully explicable with
        prosaic answers.
      </p>
      <p className="extract">
        <strong>
          8. Has the claimant provided a different explanation for the observed
          phenomena, or is it strictly a process of denying the existing
          explanation?
        </strong>{" "}
        This is a classic debate strategy—criticize your opponent and never
        affirm what you believe in order to avoid criticism. But this stratagem
        is unacceptable in science. Big Bang skeptics, for example, ignore the
        convergence of evidence of this cosmological model, focus on the few
        flaws in the accepted model, and have yet to offer a viable cosmological
        alternative that carries a preponderance of evidence in favor of it.
      </p>
      <p className="extract">
        <strong>
          9. If the claimant has proffered a new explanation, does it account
          for as many phenomena as the old explanation?
        </strong>{" "}
        The HIV-AIDS skeptics argue that lifestyle, not HIV, causes AIDS. Yet,
        to make this argument they must ignore the convergence of evidence in
        support of HIV as the causal vector in AIDS, and simultaneously ignore
        such blatant evidence as the significant correlation between the rise in
        AIDS among hemophiliacs shortly after HIV was inadvertently introduced
        into the blood supply. On top of this, their alternative theory does not
        explain nearly as much of the data as the HIV theory.
      </p>
      <p className="extract">
        <strong>
          10. Do the claimants’ personal beliefs and biases drive the
          conclusions, or vice versa?
        </strong>{" "}
        All scientists hold social, political, and <a id="page231"></a>
        ideological beliefs that could potentially slant their interpretations
        of the data, but how do those biases and beliefs affect their research?
        At some point, usually during the peer-review system, such biases and
        beliefs are rooted out, or the paper or book is rejected for
        publication. This is why one should not work in an intellectual vacuum.
        If you don’t catch the biases in your research, someone else will.
      </p>
      <p className="indent">
        There is no definitive set of criteria we can apply in determining how
        open-minded we should be when encountering new claims and ideas, but
        with mathematical calculations on the odds of weird things happening and
        with an analysis of the sorts of questions we should ask when we
        encounter weird things, we have made a start toward coming to grips with
        our weird and wonderful world. <a id="page232"></a>
      </p>
    </div>
    );
};

export default EpilogueCh;